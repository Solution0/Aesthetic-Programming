# Mini exercise 9
## Individual part
![Alt text](https://github.com/Solution0/Aesthetic-Programming/blob/Github-Desktop/Mini_ex9/Flowchart_Miniex6.png)

[Link to Mini exercise 6](https://github.com/Solution0/Aesthetic-Programming/tree/Github-Desktop/Mini_ex6)

For this exercise we were given the task to draw a flowchart around our most technically complex mini exercise to date. For this I have chosen my mini exercise #6. While its not the exercise with the longest code, it did include some complex and stacked 'if'-statements.

What was really difficult in creating this flowchart was the differentiation between Lifeform 1 and 2. This was done, same as in the code, with the variables i and j. This bridges the technical to it's presentation about it. And while it was not difficult per say I realised the lack of an 'end' in the program. It would theoretically run forever if given the opportunity. 

I could have gone deeper into what it means to 'Create a Lifeform' or what it means to touch. But I've choosen not to do this to make it more read- and suitable for presentation.

#### Reflection on groupwork
It is very easy, when you compare the three flowcharts, to determine in what part of the development each diagram is made. The two diagrams made within the group emphasizes on not limiting the potential but at the same time give us an idea of the general program. While my own is made after the programs has been made. Therefore I have a determined technical aspect that can be described in the flowchart, compared to the groups.

Algorithms is a huge part of the underlying functionality of nature, human behavior and machines. Here we use it as a way to measure progress and states. Take dishes. If clean put in cupboard, if not: clean and then put in cupboard. If given enough time everything could be made into algorithms even, as mentioned, human behavior:

![Alt text](https://github.com/Solution0/Aesthetic-Programming/blob/Github-Desktop/Mini_ex9/HumanProgramming.jpeg)

## Group part
**Made in collaboration with Jonas Nordberg, Margrethe Xie and Nanna Nørgaard**

![Alt text](https://github.com/Solution0/Aesthetic-Programming/blob/Github-Desktop/Mini_ex9/Analyzer.png)
This program is trained to analyze pictures through machine learning. It analyzes the pictures according to colors, vividness, shapes and so on… We do expect it to fail at some photos. For example with a photo of a burning house, the program would probably say that it’s a beautiful photo because of it’s vivid colors and brightness. 
The concept behind the program is to show how we humans try to teach the program about semantics, but in a logical way so that the machine can understand because machines are based on algorithms. When teaching other humans about art and semantics we only need to use words to describe and express our feelings. This question whether or not it’s ever going to be possible for computers to “have feelings” and be able to judge subjectively like we do. And also questions about how we should teach AI, how much we should expect from it and most importantly - why do we expect it to be as human as possible, to which goals are we striving to achieve from it?

#### Challenges
How do we teach the computer which picture is the most beautiful one? 
The technical aspect of making the browser analyse a set of photos in relation of how much blues ex. the photo is made of, does seem like a hard thing to do. But it is a thing we think we are capable of making, but it would take some time. To make the computer able to determine itself we need to make some kind of RGB or HSV checking on pixels. Otherwise we would have to give each picture a predetermined value.
Another thing worth thinking of, is to choose how many pictures we want the user to be able to choose from - and what this does to the program.
Do we want the user to be able to upload their own photo, and make the computer analyze the data? Or should we just put in 10 available images, that we have made the computer analyze beforehand? 

- - - -
![Alt text](https://github.com/Solution0/Aesthetic-Programming/blob/Github-Desktop/Mini_ex9/Captcha.png)
We are going create our own Captcha-program. The Captcha tries to figure whether the user of a certain program is a human or not. This is to avoid spamming or viruses in the program. The Captcha will for example ask you to write down a couple of letters to confirm your humanity. Our hope is to create an unreasonable Captcha with several levels to achieve. The levels could require to make use of sight and hearing senses or intelligence skills. The point is to make it difficult for the user to attain accessibility to the program in the end. This is to show how natural language and code/machine language differentiate from each other. The goal is in the end to show the differences between human-thinking and computational-thinking inspired by The Turing Test.

#### Challenges
It may be difficult to develop a leveling program and to sort out different lines of code to not interact with each other. But this could be overcomed by organizing and folding.
Some higher level captchas might be hard to program. But our initial idea do not include any of those.
It might be difficult to 1) make the program easy to navigate in and 2) the code itself readable. We fear that this idea might require a lot of variables to check different states of the program.
To make it interesting. Do we need some kind of randomness in challenges given? different puzzles to each level? 
